{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b0e3a9-048b-4865-8889-7f8f28c00ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, socket, threading\n",
    "from tkinter import Tk, Text, Scrollbar, Entry, Button, END, BOTH, RIGHT, LEFT, Y\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import re\n",
    "import tempfile\n",
    "import base64\n",
    "\n",
    "\n",
    "# Server information\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = 5000\n",
    "\n",
    "\n",
    "# Load environmental parameters (ie. the openai key)\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "# The list and definitions of actions the agent can select\n",
    "\n",
    "ACTION_DOC = \"\"\"\n",
    "Here are the allowed actions with parameters and descriptions:\n",
    "\n",
    "1. add_cube: size (float), location (x,y,z), rotation (x,y,z)\n",
    "   - Adds a cube mesh to the scene.\n",
    "\n",
    "2. add_sphere: radius (float), location (x,y,z)\n",
    "   - Adds a UV sphere.\n",
    "\n",
    "3. add_cylinder: radius (float), depth (float), location (x,y,z)\n",
    "   - Adds a cylinder mesh.\n",
    "\n",
    "4. add_cone: radius1 (float), radius2 (float), depth (float), location (x,y,z)\n",
    "   - Adds a cone mesh.\n",
    "\n",
    "5. add_plane: size (float), location (x,y,z)\n",
    "   - Adds a flat plane for ground or walls.\n",
    "\n",
    "7. move_object: object_name (str), location (x,y,z)\n",
    "   - Moves an existing object.\n",
    "\n",
    "8. rotate_object: object_name (str), rotation (x,y,z)\n",
    "   - Rotates an existing object.\n",
    "\n",
    "9. scale_object: object_name (str), scale (x,y,z)\n",
    "   - Scales an existing object.\n",
    "\n",
    "10. add_camera: name (str), location (x,y,z)\n",
    "    - Adds a camera to the scene.\n",
    "\n",
    "11. add_point_light: name (str), location (x,y,z), energy (float)\n",
    "    - Adds a point light.\n",
    "\n",
    "12. add_sun_light: name (str), rotation (x,y,z), strength (float)\n",
    "    - Adds a directional sun light.\n",
    "\n",
    "13. set_material_color: object_name (str), color (r,g,b,a)\n",
    "    - Sets the base color of an object's material.\n",
    "\n",
    "14. render: filepath (str)\n",
    "    - Renders the current scene to the given file path.\n",
    "\n",
    "15. list_objects: no parameters\n",
    "    - Returns a list of all objects currently in the scene.\n",
    "\n",
    "16. delete_object: object_name (str)\n",
    "    - Deletes the specified object.\n",
    "\n",
    "17. clear_scene: no parameters\n",
    "    - Removes all objects and resets the scene.\n",
    "    \n",
    "18. print_objects: no parameters\n",
    "    - Prints the current scene objects to the app log.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Send the selected command to the blender server\n",
    "def send_command(command):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.connect((HOST, PORT))\n",
    "        s.sendall(json.dumps(command).encode())\n",
    "        response = s.recv(65536)\n",
    "    return json.loads(response.decode())\n",
    "\n",
    "\n",
    "class AgentSession:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.scene_state = None            # raw list returned from server (list[str] or list[dict])\n",
    "        self.error_log = []\n",
    "        self.expected_objects = set()      # store normalized names\n",
    "\n",
    "    def log(self, msg):\n",
    "        app.append_log(msg)\n",
    "\n",
    "    # Get the list of objects from blender\n",
    "    def get_scene_objects_raw(self):\n",
    "        try:\n",
    "            resp = send_command({\"action\": \"list_objects\"})\n",
    "        except Exception as e:\n",
    "            self.log(f\"Error listing objects: {e}\")\n",
    "            return []\n",
    "\n",
    "        # If server returned a list directly\n",
    "        if isinstance(resp, list):\n",
    "            return resp\n",
    "\n",
    "        # If it's a dict, try well-known keys first\n",
    "        if isinstance(resp, dict):\n",
    "            for key in (\"objects\", \"result\", \"items\", \"data\", \"payload\"):\n",
    "                if key in resp and isinstance(resp[key], list):\n",
    "                    return resp[key]\n",
    "            # fallback: find the first list-of-things in values\n",
    "            for v in resp.values():\n",
    "                if isinstance(v, list):\n",
    "                    return v\n",
    "\n",
    "        # Log and return empty list\n",
    "        self.log(f\"Warning: unexpected list_objects response shape: {resp}\")\n",
    "        return []\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_names_from_list(lst):\n",
    "        \"\"\"\n",
    "        From a list that may contain dicts or strings, return a list of names (strings).\n",
    "        For dict entries, prefer common keys like 'name', 'object_name', 'id', 'label'.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        for item in lst:\n",
    "            if isinstance(item, dict):\n",
    "                name = item.get(\"name\") or item.get(\"object_name\") or item.get(\"id\") or item.get(\"label\")\n",
    "                if name:\n",
    "                    names.append(str(name))\n",
    "                else:\n",
    "                    # as a last resort stringify the dict (not ideal, but safe)\n",
    "                    names.append(str(item))\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "            else:\n",
    "                # convert other types safely to string\n",
    "                names.append(str(item))\n",
    "        return names\n",
    "\n",
    "    _NAME_SUFFIX_RE = re.compile(r\"^(.*?)(?:\\.\\d+)?$\")\n",
    "\n",
    "    # Normalize the name to help with comparison\n",
    "    @classmethod    \n",
    "    def _normalize_name(cls, name):\n",
    "        \"\"\"Strip Blender numeric suffixes like 'Cube.001' -> 'Cube' and trim whitespace.\"\"\"\n",
    "        if name is None:\n",
    "            return \"\"\n",
    "        s = str(name).strip()\n",
    "        m = cls._NAME_SUFFIX_RE.match(s)\n",
    "        return m.group(1) if m else s\n",
    "\n",
    "    # =================================================================================\n",
    "    # Assemble the prompt and send it to the LLM.  This is where the real logic happens\n",
    "    def ask_llm_for_commands(self):\n",
    "        goal_description = \"\\n\".join(self.conversation_history)\n",
    "\n",
    "        context = \"\"\n",
    "        if self.scene_state:\n",
    "            context += f\"Scene objects currently present: {self.scene_state}\\n\"\n",
    "        if self.error_log:\n",
    "            context += f\"Errors from last attempt: {self.error_log}\\n\"\n",
    "\n",
    "        # Define the prompt.  Include the goal (describing the agent), the commands, the history, and the format of the expect \n",
    "        # response (ie. json)\n",
    "\n",
    "        # System prompt defines the role/goals of the agent.\n",
    "        system_prompt = f\"\"\"\n",
    "You are an AI that generates JSON commands for Blender.  Your goal is to take in the command given the user and select the appropriate\n",
    "actions to take.   \n",
    "\n",
    "Each command MUST be an object with keys:\n",
    "- \"action\": (string) the action name, one of the allowed actions\n",
    "- \"params\": (object, optional) parameters for the action\n",
    "\n",
    "Do not put the action name as a key itself.\n",
    "\n",
    "{ACTION_DOC}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # User prompt is the most updated information.  \n",
    "        user_prompt = f\"\"\"\n",
    "\n",
    "User instructions so far (latest last):\n",
    "{goal_description}\n",
    "\n",
    "{context}\n",
    "\n",
    "Only consider the last statement in the conversation.  Generate ONLY the new or corrective commands needed.\n",
    "Return ONLY a raw JSON array, no code fences or markdown.\n",
    "\"\"\"\n",
    "\n",
    "        # Send prompt to gpt\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        text = resp.choices[0].message.content\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except json.JSONDecodeError:\n",
    "            self.log(f\"Invalid JSON from LLM: {text}\")\n",
    "            return []\n",
    "\n",
    "    # Parse and handle the returned instruction list\n",
    "    def process_instruction(self, user_text):\n",
    "        ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        #self.conversation_history.append(f\"[{ts}] {user_text}\")\n",
    "        self.conversation_history = f\"[{ts}] {user_text}\"\n",
    "\n",
    "        commands = self.ask_llm_for_commands()\n",
    "        all_results = []\n",
    "        new_errors = []\n",
    "\n",
    "        for cmd in commands:\n",
    "            action = cmd.get(\"action\")\n",
    "\n",
    "            # First check for local commands.  Currently the only one is print_objects\n",
    "            # Local-only print_objects\n",
    "            if action == \"print_objects\":\n",
    "                raw = self.get_scene_objects_raw()\n",
    "                self.scene_state = raw\n",
    "                self.log(\"====================\")\n",
    "                self.log(f\"Scene objects: {raw}\")\n",
    "                self.log(\"====================\")\n",
    "                continue\n",
    "\n",
    "            #  Update expected_objects BEFORE sending (store normalized names) \n",
    "            if isinstance(action, str):\n",
    "                if action.startswith(\"add_\"):\n",
    "                    # prefer an explicit name param from the LLM; otherwise infer\n",
    "                    name = cmd.get(\"params\", {}).get(\"name\")\n",
    "                    if not name:\n",
    "                        name = action.replace(\"add_\", \"\").capitalize()\n",
    "                    self.expected_objects.add(self._normalize_name(name))\n",
    "                elif action == \"delete_object\":\n",
    "                    name = cmd.get(\"params\", {}).get(\"object_name\")\n",
    "                    if name:\n",
    "                        self.expected_objects.discard(self._normalize_name(name))\n",
    "                elif action == \"clear_scene\":\n",
    "                    self.expected_objects.clear()\n",
    "\n",
    "            #  Send the command to blender to modify the scene \n",
    "            self.log(f\"Sending: {cmd}\")\n",
    "            try:\n",
    "                result = send_command(cmd)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": str(e)}\n",
    "            self.log(f\"← Result: {result}\")\n",
    "            all_results.append((cmd, result))\n",
    "            if \"error\" in result:\n",
    "                new_errors.append({\"command\": cmd, \"error\": result[\"error\"]})\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        # Update raw scene state and log it \n",
    "        raw = self.get_scene_objects_raw()\n",
    "        self.scene_state = raw\n",
    "        self.log(f\"Scene now contains: {self.scene_state}\")\n",
    "\n",
    "        # Verification step using extracted & normalized names\n",
    "        self.verify_scene()\n",
    "\n",
    "        self.error_log = new_errors\n",
    "\n",
    "    # Send a command to render the scene to a png.  \n",
    "    def render_scene(self):\n",
    "\n",
    "        tmpfile = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "        tmpfile.close()\n",
    "        try:\n",
    "            send_command({\"action\": \"render\", \"params\": {\"filepath\": tmpfile.name}})\n",
    "            self.log(f\"Rendered image saved to {tmpfile.name}\")\n",
    "            return tmpfile.name\n",
    "        except Exception as e:\n",
    "            self.log(f\"Render failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    #   Compare the expected set of objects against the current list of objects in the scene\n",
    "    def verify_scene(self):\n",
    "        \"\"\"Compare normalized Blender names to our normalized expected set.\"\"\"\n",
    "        raw = self.scene_state or []\n",
    "        names = self._extract_names_from_list(raw)\n",
    "        blender_norm = set(self._normalize_name(n) for n in names)\n",
    "        expected_norm = set(self.expected_objects)  # already normalized on insert\n",
    "\n",
    "        missing = sorted(expected_norm - blender_norm)\n",
    "        unexpected = sorted(blender_norm - expected_norm)\n",
    "\n",
    "        if not missing and not unexpected:\n",
    "            self.log(\"SUCCESS:  Verification passed: scene matches expected objects.\")\n",
    "        else:\n",
    "            if missing:\n",
    "                self.log(f\"MISSING OBJECTS: (expected but not in Blender): {missing}\")\n",
    "            if unexpected:\n",
    "                self.log(f\"UNEXPECTED OBJECT (in Blender but not expected): {unexpected}\")\n",
    "\n",
    "    # Conduct a visual rendering of the scene.  Ask an LLM if the png created matches the description\n",
    "    def evaluate_render(self, user_prompt):\n",
    "        \"\"\"\n",
    "        Ask a vision-capable LLM if the rendered image matches the user prompt.\n",
    "        \"\"\"\n",
    "        image_path = self.render_scene()\n",
    "        if not image_path:\n",
    "            self.log(\"Cannot evaluate without a render.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "\n",
    "            #with open(image_path, \"rb\") as f:\n",
    "                #img_bytes = f.read()\n",
    "\n",
    "            with open(image_path, \"rb\") as f:                \n",
    "                resp = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",  # multimodal\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": (\n",
    "                                \"You are a visual QA assistant. \"\n",
    "                                \"Given a prompt and a rendered image, \"\n",
    "                                \"state whether the image matches the prompt.\"\n",
    "                            ),\n",
    "                        },\n",
    "                        \n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": f\"Prompt: {user_prompt}\\nDoes the rendered image match this description? Answer 'yes' or 'no' and explain briefly.\"\n",
    "                                }, \n",
    "                                {\"type\": \"file\", \"file\": f} \n",
    "                            \n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0,\n",
    "                )\n",
    "            answer = resp.choices[0].message.content\n",
    "            self.log(f\"Evaluation result:\\n{answer}\")\n",
    "        except Exception as e:\n",
    "            self.log(f\"Evaluation failed: {e}\")\n",
    "\n",
    "\n",
    "# The blender app.  Allows for a multi-turn interaction.  Also has a panel to display information.  \n",
    "class BlenderAgentApp(Tk):\n",
    "    def __init__(self, agent):\n",
    "        super().__init__()\n",
    "        self.title(\"Blender Agent\")\n",
    "        self.geometry(\"700x500\")\n",
    "        self.agent = agent\n",
    "\n",
    "        self.text_area = Text(self, wrap=\"word\")\n",
    "        self.scrollbar = Scrollbar(self, command=self.text_area.yview)\n",
    "        self.text_area.configure(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.pack(side=RIGHT, fill=Y)\n",
    "        self.text_area.pack(side=LEFT, fill=BOTH, expand=True)\n",
    "\n",
    "        self.entry = Entry(self)\n",
    "        self.entry.pack(fill=\"x\", padx=5, pady=5)\n",
    "        self.entry.bind(\"<Return>\", lambda e: self.send())\n",
    "\n",
    "        self.send_button = Button(self, text=\"Send\", command=self.send)\n",
    "        self.send_button.pack(pady=5)\n",
    "        self.eval_button = Button(self, text=\"Evaluate Render\",\n",
    "                                  command=self.evaluate)\n",
    "        self.eval_button.pack(pady=5)\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Use the last user statement as the reference prompt\n",
    "        last_prompt = self.agent.conversation_history[-1] if self.agent.conversation_history else \"\"\n",
    "        threading.Thread(\n",
    "            target=self.agent.evaluate_render,\n",
    "            args=(last_prompt,),\n",
    "            daemon=True\n",
    "        ).start()\n",
    "\n",
    "    def append_log(self, msg):\n",
    "        self.text_area.insert(END, f\"{msg}\\n\")\n",
    "        self.text_area.see(END)\n",
    "\n",
    "    def send(self):\n",
    "        user_text = self.entry.get().strip()\n",
    "        if not user_text:\n",
    "            return\n",
    "        self.entry.delete(0, END)\n",
    "        self.append_log(f\"User: {user_text}\")\n",
    "        threading.Thread(\n",
    "            target=self._background_process, args=(user_text,), daemon=True\n",
    "        ).start()\n",
    "\n",
    "    def _background_process(self, text):\n",
    "        self.agent.process_instruction(text)\n",
    "\n",
    "\n",
    "# Go!\n",
    "if __name__ == \"__main__\":\n",
    "    agent = AgentSession()\n",
    "    app = BlenderAgentApp(agent)\n",
    "    app.append_log(\n",
    "        \"Blender Agent Ready. Example:\\n\"\n",
    "        \"  'Make a cube at the origin'\\n\"\n",
    "        \"  'What objects are currently in the scene?'\"\n",
    "    )\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09812ce8-6259-41a3-8e79-c8857c22e75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
